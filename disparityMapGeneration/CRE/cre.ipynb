{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HTLHDQSwaMYY"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbCJwEsgahKZ"},"outputs":[],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"id":"S15C98IRU6qp"},"source":["## Download CRE Stereo code & requirements"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1513,"status":"ok","timestamp":1701796200569,"user":{"displayName":"Andreea Pocol","userId":"16980283600985811386"},"user_tz":300},"id":"4VlCUaIJY9An","outputId":"c493ec84-ddfb-4bbe-8dfe-45b6c0c3274e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'CREStereo'...\n","remote: Enumerating objects: 80, done.\u001b[K\n","remote: Counting objects: 100% (80/80), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 80 (delta 26), reused 53 (delta 9), pack-reused 0\u001b[K\n","Receiving objects: 100% (80/80), 3.71 MiB | 6.12 MiB/s, done.\n","Resolving deltas: 100% (26/26), done.\n"]}],"source":["!git clone https://github.com/megvii-research/CREStereo.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":670028,"status":"ok","timestamp":1701796871743,"user":{"displayName":"Andreea Pocol","userId":"16980283600985811386"},"user_tz":300},"id":"L5gSEUrVZM5i","outputId":"24226249-5aa3-4725-d0fa-b09cfc1c3e0c"},"outputs":[],"source":["!pip install -r CREStereo/requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"r_ZWBgjiOdQV"},"source":["May have to resolve typo in `/content/CREStereo/nets/corr.py:39`:\n","```\n","TypeError: pad() got an unexpected keyword argument 'pad_witdth'\n","```\n","\n","Change `/content/CREStereo/test.py:99` to\n","```\n","disp_vis = disp\n","```\n","Also remove color-mapping in `/content/CREStereo/test.py:101`"]},{"cell_type":"markdown","metadata":{"id":"4moq1ECLVAP-"},"source":["## Generate left disparity map"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ml7i0moGZBlo"},"outputs":[],"source":["!python3 CREStereo/test.py --model CREStereo/crestereo_eth3d.mge --left CREStereo/im0.png --right CREStereo/im1.png --size 695x555 --output left_disparity.png\n","# !mv left_disparity.png CREStereo/img/test/roses_left_disparity.png\n"]},{"cell_type":"markdown","metadata":{"id":"ijkdC8JWVG2H"},"source":["## Generate right disparity map"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7112,"status":"ok","timestamp":1701745863688,"user":{"displayName":"Andreea Pocol","userId":"16980283600985811386"},"user_tz":300},"id":"LT8AkrlDGNPt","outputId":"c1ce058c-25e8-4c82-fece-7e8b4c4407df"},"outputs":[],"source":["# !pip install opencv-python\n","\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","'''\n","Rotate left and right disparity maps\n","'''\n","left_img = cv2.imread(\"CREStereo/img0.png\")\n","rotated_left_img = left_img[:, ::-1]\n","# cv2_imshow(rotated_left_img)\n","cv2.imwrite(\"img0_rotated.png\", rotated_left_img)\n","\n","right_img = cv2.imread(\"CREStereo/img1.png\")\n","rotated_right_img = right_img[:, ::-1]\n","# cv2_imshow(rotated_right_img)\n","cv2.imwrite(\"img1_rotated.png\", rotated_right_img)\n","\n","!mv img1_rotated.png CREStereo/img1_rotated.png\n","!mv img0_rotated.png CREStereo/img0_rotated.png\n","\n","'''\n","Generate rotated version of right disparity map\n","'''\n","!python3 CREStereo/test.py --model CREStereo/crestereo_eth3d.mge --left CREStereo/img1_rotated.png --right CREStereo/img0_rotated.png --size 695x555 --output right_disparity_rotated.png\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":536},"executionInfo":{"elapsed":474,"status":"ok","timestamp":1701745982064,"user":{"displayName":"Andreea Pocol","userId":"16980283600985811386"},"user_tz":300},"id":"cjUqlxtKQU-j","outputId":"e564025d-1436-412f-ec78-532e0d38531c"},"outputs":[],"source":["'''\n","Correct orientation of right disparity map\n","'''\n","right_disp_rotated = cv2.imread(\"right_disparity_rotated.png\")\n","right_disp = right_disp_rotated[:, ::-1]\n","cv2_imshow(right_disp)\n","cv2.imwrite(\"right_disparity.png\", right_disp)\n","\n","!mv right_disparity.png right_disparity.png"]},{"cell_type":"markdown","metadata":{"id":"KIPQtJUrVPZM"},"source":["## Convert disparity maps to grayscale"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LiSePJ3K9Coi"},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","\n","def convertRgbToGrayscale(color_image, side):\n","    # This solution is based on\n","    # https://stackoverflow.com/questions/51824718/opencv-jetmap-or-colormap-to-grayscale-reverse-applycolormap\n","    # create an inverse from the colormap to gray values\n","    gray_values = np.arange(256, dtype=np.uint8)\n","    color_values = map(tuple, cv2.applyColorMap(gray_values, cv2.COLORMAP_INFERNO).reshape(256, 3))\n","    color_to_gray_map = dict(zip(color_values, gray_values))\n","\n","    # apply the inverse map to the false color image to reconstruct the grayscale image\n","    gray_image = np.apply_along_axis(lambda bgr: color_to_gray_map[tuple(bgr)], 2, color_image)\n","\n","    # save reconstructed grayscale image\n","    cv2.imwrite(f'grayscale_disp_map_{side}.png', gray_image)\n","    return gray_image\n","\n","disp = cv2.imread(\"CREStereo/img/test/roses_left_disparity.png\", cv2.IMREAD_UNCHANGED)\n","left_disp_gray = convertRgbToGrayscale(disp, \"left\")\n","\n","cv2_imshow(left_disp_gray)\n","\n","disp = cv2.imread(\"CREStereo/img/test/roses_right_disparity.png\", cv2.IMREAD_UNCHANGED)\n","right_disp_gray = convertRgbToGrayscale(disp, \"right\")\n","\n","cv2_imshow(right_disp_gray)"]},{"cell_type":"markdown","metadata":{"id":"hhE5dj19CLRx"},"source":["# Batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dVo2UyQlALlX"},"outputs":[],"source":["!unzip test.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":158892,"status":"ok","timestamp":1701797354597,"user":{"displayName":"Andreea Pocol","userId":"16980283600985811386"},"user_tz":300},"id":"WzfCP_ylCQKf","outputId":"256aef11-9843-45f2-beda-61d0ecb95ef1"},"outputs":[],"source":["import cv2\n","from google.colab import files\n","\n","imgs = [\n","    # \"art\",\n","    \"flowerbed\",\n","    \"lilies\",\n","    \"statue\",\n","    \"sunflowers\",\n","    \"tree\",\n","    \"trees\",\n","    \"woods\",\n","    \"roses\",\n","    \"rock\",\n","    \"peaches\",\n","    \"mug\",\n","    \"grapes\"\n","]\n","\n","for img in imgs:\n","  left_img = cv2.imread(f\"test/{img}/{img}_L.png\")\n","  right_img = cv2.imread(f\"test/{img}/{img}_R.png\")\n","  x = left_img.shape[0]\n","  y = left_img.shape[1]\n","  !python3 CREStereo/test.py --model CREStereo/crestereo_eth3d.mge --left test/{img}/{img}_L.png --right test/{img}/{img}_R.png --size {x}x{y} --output test/{img}/left_disparity.png\n","\n","  rotated_left_img = left_img[:, ::-1]\n","  cv2.imwrite(f\"test/{img}/{img}_L_rotated.png\", rotated_left_img)\n","  rotated_right_img = right_img[:, ::-1]\n","  cv2.imwrite(f\"test/{img}/{img}_R_rotated.png\", rotated_right_img)\n","\n","  !python3 CREStereo/test.py --model CREStereo/crestereo_eth3d.mge --left test/{img}/{img}_R_rotated.png --right test/{img}/{img}_L_rotated.png --size {x}x{y} --output test/{img}/right_disparity_rotated.png\n","\n","  right_disp_rotated = cv2.imread(f\"test/{img}/right_disparity_rotated.png\")\n","  right_disp = right_disp_rotated[:, ::-1]\n","  cv2.imwrite(f\"test/{img}/right_disparity.png\", right_disp)\n","\n","  !rm -f /content/test/{img}/{img}_R_rotated.png\n","  !rm -f /content/test/{img}/right_disparity_rotated.png\n","  !rm -f /content/test/{img}/{img}_L_rotated.png\n","\n","!zip -r test.zip test\n","files.download(f\"test.zip\")"]},{"cell_type":"markdown","metadata":{"id":"G2NuMtG8fQ6l"},"source":["# Middlebury's test images\n","* Middlebury so images are rectified and NOT likely to be the cause of any issues\n","* quarter-sized so no scaling required - and generation should be fast\n","* test images used in evaluating generators for the stereo eval3 dataset so they're good, relevant choices"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2BH9GLBjfRww","outputId":"2a8d08ce-f758-476d-b422-134abab9c0e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading model: /content/CREStereo/crestereo_eth3d.mge\n"]}],"source":["import cv2\n","from google.colab import files\n","\n","# !unzip test.zip\n","\n","imgs = [\n","  # \"Australia\",\n","  # \"AustraliaP\", # TODO\n","  # \"Bicycle2\", # TODO\n","  \"Classroom2\",\n","  # \"Classroom2E\", # TODO\n","  \"Computer\",\n","  # \"Crusade\", # TODO\n","  # \"CrusadeP\", # TODO\n","  # \"Djembe\", # TODO\n","  # \"DjembeL\", # TODO\n","  \"Hoops\",\n","  # \"Livingroom\",\n","  # \"Newkuba\", # TODO\n","  \"Plants\",\n","  \"Staircase\"\n","]\n","\n","for img in imgs:\n","  left_img = cv2.imread(f\"test/{img}/im0.png\")\n","  right_img = cv2.imread(f\"test/{img}/im1.png\")\n","  x = left_img.shape[0]\n","  y = left_img.shape[1]\n","  !python3 CREStereo/test.py --model CREStereo/crestereo_eth3d.mge --left test/{img}/im0.png --right test/{img}/im1.png --size {x}x{y} --output {img}/left_disparity.png\n","\n","  rotated_left_img = left_img[:, ::-1]\n","  cv2.imwrite(f\"test/{img}/im0_rotated.png\", rotated_left_img)\n","  rotated_right_img = right_img[:, ::-1]\n","  cv2.imwrite(f\"test/{img}/im1_rotated.png\", rotated_right_img)\n","\n","  !python3 CREStereo/test.py --model CREStereo/crestereo_eth3d.mge --left test/{img}/im1_rotated.png --right test/{img}/im0_rotated.png --size {x}x{y} --output {img}/right_disparity_rotated.png\n","\n","  right_disp_rotated = cv2.imread(f\"{img}/right_disparity_rotated.png\")\n","  right_disp = right_disp_rotated[:, ::-1]\n","  cv2.imwrite(f\"{img}/right_disparity.png\", right_disp)\n","\n","  !rm -f /content/test/{img}/im1_rotated.png\n","  !rm -f /content/test/{img}/im0_rotated.png\n","\n","# !zip -r test.zip test\n","# files.download(f\"test.zip\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNt8tzPveF0+5+gYIMuITye","collapsed_sections":["4moq1ECLVAP-","ijkdC8JWVG2H","KIPQtJUrVPZM","G2NuMtG8fQ6l"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
